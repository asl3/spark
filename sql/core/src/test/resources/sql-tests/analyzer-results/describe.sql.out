-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE intervals (
  id INT,
  interval INTERVAL DAY TO HOUR,
  age INT
)
PARTITIONED BY (id, age)
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`intervals`"
  }
}


-- !query
INSERT INTO intervals (id, interval, age)
VALUES
  (1, INTERVAL '1 2' DAY TO HOUR, 22),
  (2, INTERVAL '-3 4' DAY TO HOUR, 12),
  (3, INTERVAL '10 12' DAY TO HOUR, 0)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/intervals, false, [id#x, age#x], Parquet, [path=file:[not included in comparison]/{warehouse_dir}/intervals], Append, `spark_catalog`.`default`.`intervals`, org.apache.spark.sql.execution.datasources.CatalogFileIndex(file:[not included in comparison]/{warehouse_dir}/intervals), [interval, id, age]
+- Project [interval#x, id#x, age#x]
   +- Project [col1#x AS id#x, col2#x AS interval#x, col3#x AS age#x]
      +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
DESCRIBE FORMATTED intervals
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`intervals`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESCRIBE FORMATTED intervals PARTITION (id=2, age=12)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`intervals`, [id=2, age=12], true, false, [col_name#x, data_type#x, comment#x]


-- !query
CREATE TABLE complex (
   a STRING,
   b INT,
   c STRUCT<name: STRING, details: STRUCT<age: INT, address: STRING>>,
   d STRING
) USING parquet
OPTIONS (a '1', b '2', password 'password')
PARTITIONED BY (b, d)
COMMENT 'table_comment'
TBLPROPERTIES (t 'test', password 'password')
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`complex`"
  }
}


-- !query
DESCRIBE FORMATTED complex AS JSON
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "b, d",
    "specKeys" : "",
    "tableName" : "`spark_catalog`.`default`.`complex`"
  }
}


-- !query
CREATE TABLE t (a STRING, b INT, c STRING, d STRING) USING parquet
  OPTIONS (a '1', b '2', password 'password')
  PARTITIONED BY (c, d) CLUSTERED BY (a) SORTED BY (b ASC) INTO 2 BUCKETS
  COMMENT 'table_comment'
  TBLPROPERTIES (t 'test', password 'password')
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
CREATE TEMPORARY VIEW temp_v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `temp_v`, SELECT * FROM t, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [a#x, b#x, c#x, d#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[a#x,b#x,c#x,d#x] parquet


-- !query
CREATE TEMPORARY VIEW temp_Data_Source_View
  USING org.apache.spark.sql.sources.DDLScanSource
  OPTIONS (
    From '1',
    To '10',
    Table 'test1')
-- !query analysis
CreateTempViewUsing [tableIdent:`temp_Data_Source_View` replace:false provider:org.apache.spark.sql.sources.DDLScanSource Map(From -> 1, To -> 10, Table -> test1)


-- !query
CREATE VIEW v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, b#x, c#x, d#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[a#x,b#x,c#x,d#x] parquet


-- !query
ALTER TABLE t SET TBLPROPERTIES (e = '3')
-- !query analysis
AlterTableSetPropertiesCommand `spark_catalog`.`default`.`t`, [e=3], false


-- !query
ALTER TABLE t ADD PARTITION (c='Us', d=1)
-- !query analysis
AlterTableAddPartitionCommand `spark_catalog`.`default`.`t`, [(Map(c -> Us, d -> 1),None)], false


-- !query
DESCRIBE t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
DESCRIBE t AS JSON
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "",
    "tableName" : "`spark_catalog`.`default`.`t`"
  }
}


-- !query
DESC default.t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t AS JSON
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "",
    "tableName" : "`spark_catalog`.`default`.`t`"
  }
}


-- !query
DESC EXTENDED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t AS JSON
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "",
    "tableName" : "`spark_catalog`.`default`.`t`"
  }
}


-- !query
ALTER TABLE t UNSET TBLPROPERTIES (e)
-- !query analysis
AlterTableUnsetPropertiesCommand `spark_catalog`.`default`.`t`, [e], false, false


-- !query
DESC EXTENDED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
ALTER TABLE t UNSET TBLPROPERTIES (comment)
-- !query analysis
AlterTableUnsetPropertiesCommand `spark_catalog`.`default`.`t`, [comment], false, false


-- !query
DESC EXTENDED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC t PARTITION (c='Us', d=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], false, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC t PARTITION (c='Us', d=1) AS JSON
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], false, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t PARTITION (c='Us', d=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t PARTITION (c='Us', d=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t PARTITION (C='Us', D=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [C=Us, D=1], true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t PARTITION (C='Us', D=1) AS JSON
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [C=Us, D=1], true, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC t PARTITION (c='Us', d=2)
-- !query analysis
org.apache.spark.sql.catalyst.analysis.NoSuchPartitionException
{
  "errorClass" : "PARTITIONS_NOT_FOUND",
  "sqlState" : "428FT",
  "messageParameters" : {
    "partitionList" : "PARTITION (`c` = Us, `d` = 2)",
    "tableName" : "`default`.`t`"
  }
}


-- !query
DESC t PARTITION (c='Us', d=2) AS JSON
-- !query analysis
org.apache.spark.sql.catalyst.analysis.NoSuchPartitionException
{
  "errorClass" : "PARTITIONS_NOT_FOUND",
  "sqlState" : "428FT",
  "messageParameters" : {
    "partitionList" : "PARTITION (`c` = Us, `d` = 2)",
    "tableName" : "`default`.`t`"
  }
}


-- !query
DESC t PARTITION (c='Us')
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "c",
    "tableName" : "`spark_catalog`.`default`.`t`"
  }
}


-- !query
DESC t PARTITION (c='Us', d)
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_SQL_SYNTAX.EMPTY_PARTITION_VALUE",
  "sqlState" : "42000",
  "messageParameters" : {
    "partKey" : "`d`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 28,
    "fragment" : "DESC t PARTITION (c='Us', d)"
  } ]
}


-- !query
DESC temp_v
-- !query analysis
DescribeTableCommand `temp_v`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC temp_v AS JSON
-- !query analysis
DescribeTableCommand `temp_v`, false, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE temp_v
-- !query analysis
DescribeTableCommand `temp_v`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE temp_v AS JSON
-- !query analysis
DescribeTableCommand `temp_v`, false, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED temp_v
-- !query analysis
DescribeTableCommand `temp_v`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED temp_v
-- !query analysis
DescribeTableCommand `temp_v`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC temp_Data_Source_View
-- !query analysis
DescribeTableCommand `temp_Data_Source_View`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC temp_v PARTITION (c='Us', d=1)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "FORBIDDEN_OPERATION",
  "sqlState" : "42809",
  "messageParameters" : {
    "objectName" : "`temp_v`",
    "objectType" : "TEMPORARY VIEW",
    "statement" : "DESC PARTITION"
  }
}


-- !query
DESC v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED v AS JSON
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC v PARTITION (c='Us', d=1)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "FORBIDDEN_OPERATION",
  "sqlState" : "42809",
  "messageParameters" : {
    "objectName" : "`v`",
    "objectType" : "VIEW",
    "statement" : "DESC PARTITION"
  }
}


-- !query
DESC v PARTITION (c='Us', d=1) AS JSON
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, [c=Us, d=1], false, true, [col_name#x, data_type#x, comment#x]


-- !query
EXPLAIN DESC t
-- !query analysis
ExplainCommand 'DescribeRelation false, false, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN DESC t AS JSON
-- !query analysis
ExplainCommand 'DescribeRelation false, true, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN DESC EXTENDED t
-- !query analysis
ExplainCommand 'DescribeRelation true, false, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN EXTENDED DESC t
-- !query analysis
ExplainCommand 'DescribeRelation false, false, [col_name#x, data_type#x, comment#x], ExtendedMode


-- !query
EXPLAIN DESCRIBE t b
-- !query analysis
ExplainCommand 'DescribeColumn 'b, false, false, [info_name#x, info_value#x], SimpleMode


-- !query
EXPLAIN DESCRIBE t PARTITION (c='Us', d=2)
-- !query analysis
ExplainCommand 'DescribeRelation [c=Us, d=2], false, false, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN DESCRIBE t PARTITION (c='Us', d=2) AS JSON
-- !query analysis
ExplainCommand 'DescribeRelation [c=Us, d=2], false, true, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
DROP TABLE t
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
DROP VIEW temp_v
-- !query analysis
DropTempViewCommand temp_v


-- !query
DROP VIEW temp_Data_Source_View
-- !query analysis
DropTempViewCommand temp_Data_Source_View


-- !query
DROP VIEW v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, false, true, false


-- !query
CREATE TABLE d (a STRING DEFAULT 'default-value', b INT DEFAULT 42) USING parquet COMMENT 'table_comment'
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`d`"
  }
}


-- !query
DESC d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC d AS JSON
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, false, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE EXTENDED d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE EXTENDED d AS JSON
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
CREATE TABLE e (a STRING DEFAULT CONCAT('a\n b\n ', 'c\n d'), b INT DEFAULT 42) USING parquet COMMENT 'table_comment'
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`e`"
  }
}


-- !query
DESC e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC e AS JSON
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, false, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE EXTENDED e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE FORMATTED e AS JSON
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE TABLE t2 (
    a STRING,
    b INT,
    c STRING,
    d STRING
)
USING parquet
OPTIONS (
    a '1',
    b '2',
    password 'password'
)
PARTITIONED BY (c, d)
CLUSTERED BY (a) SORTED BY (b ASC) INTO 2 BUCKETS
COMMENT 'table_comment'
TBLPROPERTIES (
    t 'test',
    password 'password'
)
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`t2`"
  }
}


-- !query
DESC t2
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t2`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC t2 as json
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "",
    "tableName" : "`spark_catalog`.`default`.`t2`"
  }
}
