-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE intervals (
  id INT,
  interval INTERVAL DAY TO HOUR,
  age INT
)
PARTITIONED BY (id, age)
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO intervals (id, interval, age)
VALUES
  (1, INTERVAL '1 2' DAY TO HOUR, 22),
  (2, INTERVAL '-3 4' DAY TO HOUR, 12),
  (3, INTERVAL '10 12' DAY TO HOUR, 0)
-- !query schema
struct<>
-- !query output



-- !query
DESCRIBE FORMATTED intervals
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
interval            	interval day to hour	                    
id                  	int                 	                    
age                 	int                 	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
id                  	int                 	                    
age                 	int                 	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	intervals           	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	parquet             	                    
Location [not included in comparison]/{warehouse_dir}/intervals	                    
Partition Provider  	Catalog


-- !query
DESCRIBE FORMATTED intervals PARTITION (id=2, age=12)
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
interval            	interval day to hour	                    
id                  	int                 	                    
age                 	int                 	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
id                  	int                 	                    
age                 	int                 	                    
                    	                    	                    
# Detailed Partition Information	                    	                    
Database            	default             	                    
Table               	intervals           	                    
Partition Values    	[id=2, age=12]      	                    
Location [not included in comparison]/{warehouse_dir}/intervals/id=2/age=12	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
                    	                    	                    
# Storage Information	                    	                    
Location [not included in comparison]/{warehouse_dir}/intervals


-- !query
CREATE TABLE complex (
   a STRING,
   b INT,
   c STRUCT<name: STRING, details: STRUCT<age: INT, address: STRING>>,
   d STRING
) USING parquet
OPTIONS (a '1', b '2', password 'password')
PARTITIONED BY (b, d)
COMMENT 'table_comment'
TBLPROPERTIES (t 'test', password 'password')
-- !query schema
struct<>
-- !query output



-- !query
DESCRIBE FORMATTED complex AS JSON
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "b, d",
    "specKeys" : "",
    "tableName" : "`spark_catalog`.`default`.`complex`"
  }
}


-- !query
CREATE TABLE t (a STRING, b INT, c STRING, d STRING) USING parquet
  OPTIONS (a '1', b '2', password 'password')
  PARTITIONED BY (c, d) CLUSTERED BY (a) SORTED BY (b ASC) INTO 2 BUCKETS
  COMMENT 'table_comment'
  TBLPROPERTIES (t 'test', password 'password')
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY VIEW temp_v AS SELECT * FROM t
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY VIEW temp_Data_Source_View
  USING org.apache.spark.sql.sources.DDLScanSource
  OPTIONS (
    From '1',
    To '10',
    Table 'test1')
-- !query schema
struct<>
-- !query output



-- !query
CREATE VIEW v AS SELECT * FROM t
-- !query schema
struct<>
-- !query output



-- !query
ALTER TABLE t SET TBLPROPERTIES (e = '3')
-- !query schema
struct<>
-- !query output



-- !query
ALTER TABLE t ADD PARTITION (c='Us', d=1)
-- !query schema
struct<>
-- !query output



-- !query
DESCRIBE t
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
c                   	string              	                    
d                   	string


-- !query
DESCRIBE t AS JSON
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "",
    "tableName" : "`spark_catalog`.`default`.`t`"
  }
}


-- !query
DESC default.t
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
c                   	string              	                    
d                   	string


-- !query
DESC TABLE t
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
c                   	string              	                    
d                   	string


-- !query
DESC FORMATTED t
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
c                   	string              	                    
d                   	string              	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	t                   	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	parquet             	                    
Num Buckets         	2                   	                    
Bucket Columns      	[`a`]               	                    
Sort Columns        	[`b`]               	                    
Comment             	table_comment       	                    
Table Properties    	[e=3, password=*********(redacted), t=test]	                    
Location [not included in comparison]/{warehouse_dir}/t	                    
Storage Properties  	[a=1, b=2, password=*********(redacted)]	                    
Partition Provider  	Catalog


-- !query
DESC FORMATTED t AS JSON
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "",
    "tableName" : "`spark_catalog`.`default`.`t`"
  }
}


-- !query
DESC EXTENDED t
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
c                   	string              	                    
d                   	string              	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	t                   	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	parquet             	                    
Num Buckets         	2                   	                    
Bucket Columns      	[`a`]               	                    
Sort Columns        	[`b`]               	                    
Comment             	table_comment       	                    
Table Properties    	[e=3, password=*********(redacted), t=test]	                    
Location [not included in comparison]/{warehouse_dir}/t	                    
Storage Properties  	[a=1, b=2, password=*********(redacted)]	                    
Partition Provider  	Catalog


-- !query
DESC EXTENDED t AS JSON
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "",
    "tableName" : "`spark_catalog`.`default`.`t`"
  }
}


-- !query
ALTER TABLE t UNSET TBLPROPERTIES (e)
-- !query schema
struct<>
-- !query output



-- !query
DESC EXTENDED t
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
c                   	string              	                    
d                   	string              	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	t                   	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	parquet             	                    
Num Buckets         	2                   	                    
Bucket Columns      	[`a`]               	                    
Sort Columns        	[`b`]               	                    
Comment             	table_comment       	                    
Table Properties    	[password=*********(redacted), t=test]	                    
Location [not included in comparison]/{warehouse_dir}/t	                    
Storage Properties  	[a=1, b=2, password=*********(redacted)]	                    
Partition Provider  	Catalog


-- !query
ALTER TABLE t UNSET TBLPROPERTIES (comment)
-- !query schema
struct<>
-- !query output



-- !query
DESC EXTENDED t
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
c                   	string              	                    
d                   	string              	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	t                   	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	parquet             	                    
Num Buckets         	2                   	                    
Bucket Columns      	[`a`]               	                    
Sort Columns        	[`b`]               	                    
Table Properties    	[password=*********(redacted), t=test]	                    
Location [not included in comparison]/{warehouse_dir}/t	                    
Storage Properties  	[a=1, b=2, password=*********(redacted)]	                    
Partition Provider  	Catalog


-- !query
DESC t PARTITION (c='Us', d=1)
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
c                   	string              	                    
d                   	string


-- !query
DESC t PARTITION (c='Us', d=1) AS JSON
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
{"columns":[{"id":0,"name":"a","type":{"type":"string"},"comment":null},{"id":1,"name":"b","type":{"type":"integer"},"comment":null},{"id":2,"name":"c","type":{"type":"string"},"comment":null},{"id":3,"name":"d","type":{"type":"string"},"comment":null}],"database":"default","table":"t","num_buckets":"2","bucket_columns":"[`a`]","sort_columns":"[`b`]","partition_values":"[c=Us, d=1]","location": [not included in comparison]/{warehouse_dir}/t/c=Us/d=1","storage_properties":"[a=1, b=2, password=*********(redacted)]","created_time [not included in comparison]":"None","last_access [not included in comparison]":"None","partition_columns":[{"id":0,"name":"c","type":{"type":"string"},"comment":null},{"id":1,"name":"d","type":{"type":"string"},"comment":null}]}


-- !query
DESC EXTENDED t PARTITION (c='Us', d=1)
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
c                   	string              	                    
d                   	string              	                    
                    	                    	                    
# Detailed Partition Information	                    	                    
Database            	default             	                    
Table               	t                   	                    
Partition Values    	[c=Us, d=1]         	                    
Location [not included in comparison]/{warehouse_dir}/t/c=Us/d=1	                    
Storage Properties  	[a=1, b=2, password=*********(redacted)]	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
                    	                    	                    
# Storage Information	                    	                    
Num Buckets         	2                   	                    
Bucket Columns      	[`a`]               	                    
Sort Columns        	[`b`]               	                    
Location [not included in comparison]/{warehouse_dir}/t	                    
Storage Properties  	[a=1, b=2, password=*********(redacted)]


-- !query
DESC FORMATTED t PARTITION (c='Us', d=1)
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
c                   	string              	                    
d                   	string              	                    
                    	                    	                    
# Detailed Partition Information	                    	                    
Database            	default             	                    
Table               	t                   	                    
Partition Values    	[c=Us, d=1]         	                    
Location [not included in comparison]/{warehouse_dir}/t/c=Us/d=1	                    
Storage Properties  	[a=1, b=2, password=*********(redacted)]	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
                    	                    	                    
# Storage Information	                    	                    
Num Buckets         	2                   	                    
Bucket Columns      	[`a`]               	                    
Sort Columns        	[`b`]               	                    
Location [not included in comparison]/{warehouse_dir}/t	                    
Storage Properties  	[a=1, b=2, password=*********(redacted)]


-- !query
DESC EXTENDED t PARTITION (C='Us', D=1)
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
c                   	string              	                    
d                   	string              	                    
                    	                    	                    
# Detailed Partition Information	                    	                    
Database            	default             	                    
Table               	t                   	                    
Partition Values    	[c=Us, d=1]         	                    
Location [not included in comparison]/{warehouse_dir}/t/c=Us/d=1	                    
Storage Properties  	[a=1, b=2, password=*********(redacted)]	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
                    	                    	                    
# Storage Information	                    	                    
Num Buckets         	2                   	                    
Bucket Columns      	[`a`]               	                    
Sort Columns        	[`b`]               	                    
Location [not included in comparison]/{warehouse_dir}/t	                    
Storage Properties  	[a=1, b=2, password=*********(redacted)]


-- !query
DESC EXTENDED t PARTITION (C='Us', D=1) AS JSON
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
{"columns":[{"id":0,"name":"a","type":{"type":"string"},"comment":null},{"id":1,"name":"b","type":{"type":"integer"},"comment":null},{"id":2,"name":"c","type":{"type":"string"},"comment":null},{"id":3,"name":"d","type":{"type":"string"},"comment":null}],"database":"default","table":"t","num_buckets":"2","bucket_columns":"[`a`]","sort_columns":"[`b`]","partition_values":"[c=Us, d=1]","location": [not included in comparison]/{warehouse_dir}/t/c=Us/d=1","storage_properties":"[a=1, b=2, password=*********(redacted)]","created_time [not included in comparison]":"None","last_access [not included in comparison]":"None","partition_columns":[{"id":0,"name":"c","type":{"type":"string"},"comment":null},{"id":1,"name":"d","type":{"type":"string"},"comment":null}]}


-- !query
DESC t PARTITION (c='Us', d=2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.NoSuchPartitionException
{
  "errorClass" : "PARTITIONS_NOT_FOUND",
  "sqlState" : "428FT",
  "messageParameters" : {
    "partitionList" : "PARTITION (`c` = Us, `d` = 2)",
    "tableName" : "`default`.`t`"
  }
}


-- !query
DESC t PARTITION (c='Us', d=2) AS JSON
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.NoSuchPartitionException
{
  "errorClass" : "PARTITIONS_NOT_FOUND",
  "sqlState" : "428FT",
  "messageParameters" : {
    "partitionList" : "PARTITION (`c` = Us, `d` = 2)",
    "tableName" : "`default`.`t`"
  }
}


-- !query
DESC t PARTITION (c='Us')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "c",
    "tableName" : "`spark_catalog`.`default`.`t`"
  }
}


-- !query
DESC t PARTITION (c='Us', d)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_SQL_SYNTAX.EMPTY_PARTITION_VALUE",
  "sqlState" : "42000",
  "messageParameters" : {
    "partKey" : "`d`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 28,
    "fragment" : "DESC t PARTITION (c='Us', d)"
  } ]
}


-- !query
DESC temp_v
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string


-- !query
DESC temp_v AS JSON
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
{"columns":[{"id":0,"name":"a","type":{"type":"string"},"comment":null},{"id":1,"name":"b","type":{"type":"integer"},"comment":null},{"id":2,"name":"c","type":{"type":"string"},"comment":null},{"id":3,"name":"d","type":{"type":"string"},"comment":null}]}


-- !query
DESC TABLE temp_v
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string


-- !query
DESC TABLE temp_v AS JSON
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
{"columns":[{"id":0,"name":"a","type":{"type":"string"},"comment":null},{"id":1,"name":"b","type":{"type":"integer"},"comment":null},{"id":2,"name":"c","type":{"type":"string"},"comment":null},{"id":3,"name":"d","type":{"type":"string"},"comment":null}]}


-- !query
DESC FORMATTED temp_v
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string


-- !query
DESC EXTENDED temp_v
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string


-- !query
DESC temp_Data_Source_View
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
intType             	int                 	test comment test1  
stringType          	string              	                    
dateType            	date                	                    
timestampType       	timestamp           	                    
doubleType          	double              	                    
bigintType          	bigint              	                    
tinyintType         	tinyint             	                    
decimalType         	decimal(10,0)       	                    
fixedDecimalType    	decimal(5,1)        	                    
binaryType          	binary              	                    
booleanType         	boolean             	                    
smallIntType        	smallint            	                    
floatType           	float               	                    
mapType             	map<string,string>  	                    
arrayType           	array<string>       	                    
structType          	struct<f1:string,f2:int>


-- !query
DESC temp_v PARTITION (c='Us', d=1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "FORBIDDEN_OPERATION",
  "sqlState" : "42809",
  "messageParameters" : {
    "objectName" : "`temp_v`",
    "objectType" : "TEMPORARY VIEW",
    "statement" : "DESC PARTITION"
  }
}


-- !query
DESC v
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string


-- !query
DESC TABLE v
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string


-- !query
DESC FORMATTED v
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	v                   	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	VIEW                	                    
View Text           	SELECT * FROM t     	                    
View Original Text  	SELECT * FROM t     	                    
View Schema Mode    	COMPENSATION        	                    
View Catalog and Namespace	spark_catalog.default	                    
View Query Output Columns	[a, b, c, d]


-- !query
DESC FORMATTED v AS JSON
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
{"columns":[{"id":0,"name":"a","type":{"type":"string"},"comment":null},{"id":1,"name":"b","type":{"type":"integer"},"comment":null},{"id":2,"name":"c","type":{"type":"string"},"comment":null},{"id":3,"name":"d","type":{"type":"string"},"comment":null}],"catalog":"spark_catalog","database":"default","table":"v","created_time [not included in comparison]":"None","last_access [not included in comparison]":"None","created_by [not included in comparison]":"None","type":"VIEW","view_text":"SELECT * FROM t","view_original_text":"SELECT * FROM t","view_schema_mode":"COMPENSATION","view_catalog_and_namespace":"spark_catalog.default","view_query_output_columns":"[a, b, c, d]"}


-- !query
DESC EXTENDED v
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	v                   	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	VIEW                	                    
View Text           	SELECT * FROM t     	                    
View Original Text  	SELECT * FROM t     	                    
View Schema Mode    	COMPENSATION        	                    
View Catalog and Namespace	spark_catalog.default	                    
View Query Output Columns	[a, b, c, d]


-- !query
DESC v PARTITION (c='Us', d=1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "FORBIDDEN_OPERATION",
  "sqlState" : "42809",
  "messageParameters" : {
    "objectName" : "`v`",
    "objectType" : "VIEW",
    "statement" : "DESC PARTITION"
  }
}


-- !query
DESC v PARTITION (c='Us', d=1) AS JSON
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
{"columns":[{"id":0,"name":"a","type":{"type":"string"},"comment":null},{"id":1,"name":"b","type":{"type":"integer"},"comment":null},{"id":2,"name":"c","type":{"type":"string"},"comment":null},{"id":3,"name":"d","type":{"type":"string"},"comment":null}],"catalog":"spark_catalog","database":"default","table":"v","created_time [not included in comparison]":"None","last_access [not included in comparison]":"None","created_by [not included in comparison]":"None","type":"VIEW","view_text":"SELECT * FROM t","view_original_text":"SELECT * FROM t","view_schema_mode":"COMPENSATION","view_catalog_and_namespace":"spark_catalog.default","view_query_output_columns":"[a, b, c, d]"}


-- !query
EXPLAIN DESC t
-- !query schema
struct<plan:string>
-- !query output
== Physical Plan ==
Execute DescribeTableCommand
   +- DescribeTableCommand `spark_catalog`.`default`.`t`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
EXPLAIN DESC t AS JSON
-- !query schema
struct<plan:string>
-- !query output
== Physical Plan ==
Execute DescribeTableCommand
   +- DescribeTableCommand `spark_catalog`.`default`.`t`, false, true, [col_name#x, data_type#x, comment#x]


-- !query
EXPLAIN DESC EXTENDED t
-- !query schema
struct<plan:string>
-- !query output
== Physical Plan ==
Execute DescribeTableCommand
   +- DescribeTableCommand `spark_catalog`.`default`.`t`, true, false, [col_name#x, data_type#x, comment#x]


-- !query
EXPLAIN EXTENDED DESC t
-- !query schema
struct<plan:string>
-- !query output
== Parsed Logical Plan ==
'DescribeRelation false, false, [col_name#x, data_type#x, comment#x]
+- 'UnresolvedTableOrView [t], DESCRIBE TABLE, true

== Analyzed Logical Plan ==
col_name: string, data_type: string, comment: string
DescribeTableCommand `spark_catalog`.`default`.`t`, false, false, [col_name#x, data_type#x, comment#x]

== Optimized Logical Plan ==
DescribeTableCommand `spark_catalog`.`default`.`t`, false, false, [col_name#x, data_type#x, comment#x]

== Physical Plan ==
Execute DescribeTableCommand
   +- DescribeTableCommand `spark_catalog`.`default`.`t`, false, false, [col_name#x, data_type#x, comment#x]


-- !query
EXPLAIN DESCRIBE t b
-- !query schema
struct<plan:string>
-- !query output
== Physical Plan ==
Execute DescribeColumnCommand
   +- DescribeColumnCommand `spark_catalog`.`default`.`t`, [spark_catalog, default, t, b], false, false, [info_name#x, info_value#x]


-- !query
EXPLAIN DESCRIBE t PARTITION (c='Us', d=2)
-- !query schema
struct<plan:string>
-- !query output
== Physical Plan ==
Execute DescribeTableCommand
   +- DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=2], false, false, [col_name#x, data_type#x, comment#x]


-- !query
EXPLAIN DESCRIBE t PARTITION (c='Us', d=2) AS JSON
-- !query schema
struct<plan:string>
-- !query output
== Physical Plan ==
Execute DescribeTableCommand
   +- DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=2], false, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE t
-- !query schema
struct<>
-- !query output



-- !query
DROP VIEW temp_v
-- !query schema
struct<>
-- !query output



-- !query
DROP VIEW temp_Data_Source_View
-- !query schema
struct<>
-- !query output



-- !query
DROP VIEW v
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE d (a STRING DEFAULT 'default-value', b INT DEFAULT 42) USING parquet COMMENT 'table_comment'
-- !query schema
struct<>
-- !query output



-- !query
DESC d
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
                    	                    	                    
# Column Default Values	                    	                    
a                   	string              	'default-value'     
b                   	int                 	42


-- !query
DESC d AS JSON
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
{"columns":[{"id":0,"name":"a","type":{"type":"string"},"comment":null,"default_value":"'default-value'"},{"id":1,"name":"b","type":{"type":"integer"},"comment":null,"default_value":"42"}],"catalog":"spark_catalog","database":"default","table":"d","created_time [not included in comparison]":"None","last_access [not included in comparison]":"None","created_by [not included in comparison]":"None","type":"MANAGED","provider":"parquet","comment":"table_comment","location": [not included in comparison]/{warehouse_dir}/d"}


-- !query
DESC EXTENDED d
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	d                   	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	parquet             	                    
Comment             	table_comment       	                    
Location [not included in comparison]/{warehouse_dir}/d	                    
                    	                    	                    
# Column Default Values	                    	                    
a                   	string              	'default-value'     
b                   	int                 	42


-- !query
DESC TABLE EXTENDED d
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	d                   	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	parquet             	                    
Comment             	table_comment       	                    
Location [not included in comparison]/{warehouse_dir}/d	                    
                    	                    	                    
# Column Default Values	                    	                    
a                   	string              	'default-value'     
b                   	int                 	42


-- !query
DESC TABLE EXTENDED d AS JSON
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
{"columns":[{"id":0,"name":"a","type":{"type":"string"},"comment":null,"default_value":"'default-value'"},{"id":1,"name":"b","type":{"type":"integer"},"comment":null,"default_value":"42"}],"catalog":"spark_catalog","database":"default","table":"d","created_time [not included in comparison]":"None","last_access [not included in comparison]":"None","created_by [not included in comparison]":"None","type":"MANAGED","provider":"parquet","comment":"table_comment","location": [not included in comparison]/{warehouse_dir}/d"}


-- !query
DESC FORMATTED d
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	d                   	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	parquet             	                    
Comment             	table_comment       	                    
Location [not included in comparison]/{warehouse_dir}/d	                    
                    	                    	                    
# Column Default Values	                    	                    
a                   	string              	'default-value'     
b                   	int                 	42


-- !query
CREATE TABLE e (a STRING DEFAULT CONCAT('a\n b\n ', 'c\n d'), b INT DEFAULT 42) USING parquet COMMENT 'table_comment'
-- !query schema
struct<>
-- !query output



-- !query
DESC e
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
                    	                    	                    
# Column Default Values	                    	                    
a                   	string              	CONCAT('a\n b\n ', 'c\n d')
b                   	int                 	42


-- !query
DESC e AS JSON
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
{"columns":[{"id":0,"name":"a","type":{"type":"string"},"comment":null,"default_value":"CONCAT('a\n b\n ', 'c\n d')"},{"id":1,"name":"b","type":{"type":"integer"},"comment":null,"default_value":"42"}],"catalog":"spark_catalog","database":"default","table":"e","created_time [not included in comparison]":"None","last_access [not included in comparison]":"None","created_by [not included in comparison]":"None","type":"MANAGED","provider":"parquet","comment":"table_comment","location": [not included in comparison]/{warehouse_dir}/e"}


-- !query
DESC EXTENDED e
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	e                   	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	parquet             	                    
Comment             	table_comment       	                    
Location [not included in comparison]/{warehouse_dir}/e	                    
                    	                    	                    
# Column Default Values	                    	                    
a                   	string              	CONCAT('a\n b\n ', 'c\n d')
b                   	int                 	42


-- !query
DESC TABLE EXTENDED e
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	e                   	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	parquet             	                    
Comment             	table_comment       	                    
Location [not included in comparison]/{warehouse_dir}/e	                    
                    	                    	                    
# Column Default Values	                    	                    
a                   	string              	CONCAT('a\n b\n ', 'c\n d')
b                   	int                 	42


-- !query
DESC FORMATTED e
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	default             	                    
Table               	e                   	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	parquet             	                    
Comment             	table_comment       	                    
Location [not included in comparison]/{warehouse_dir}/e	                    
                    	                    	                    
# Column Default Values	                    	                    
a                   	string              	CONCAT('a\n b\n ', 'c\n d')
b                   	int                 	42


-- !query
DESC TABLE FORMATTED e AS JSON
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
{"columns":[{"id":0,"name":"a","type":{"type":"string"},"comment":null,"default_value":"CONCAT('a\n b\n ', 'c\n d')"},{"id":1,"name":"b","type":{"type":"integer"},"comment":null,"default_value":"42"}],"catalog":"spark_catalog","database":"default","table":"e","created_time [not included in comparison]":"None","last_access [not included in comparison]":"None","created_by [not included in comparison]":"None","type":"MANAGED","provider":"parquet","comment":"table_comment","location": [not included in comparison]/{warehouse_dir}/e"}


-- !query
CREATE TABLE t2 (
    a STRING,
    b INT,
    c STRING,
    d STRING
)
USING parquet
OPTIONS (
    a '1',
    b '2',
    password 'password'
)
PARTITIONED BY (c, d)
CLUSTERED BY (a) SORTED BY (b ASC) INTO 2 BUCKETS
COMMENT 'table_comment'
TBLPROPERTIES (
    t 'test',
    password 'password'
)
-- !query schema
struct<>
-- !query output



-- !query
DESC t2
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
a                   	string              	                    
b                   	int                 	                    
c                   	string              	                    
d                   	string              	                    
# Partition Information	                    	                    
# col_name          	data_type           	comment             
c                   	string              	                    
d                   	string


-- !query
DESC t2 as json
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "",
    "tableName" : "`spark_catalog`.`default`.`t2`"
  }
}
